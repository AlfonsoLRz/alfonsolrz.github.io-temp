<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Alfonso López Ruiz </title> <meta name="author" content="Alfonso López Ruiz"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alfonsolrz.github.io/publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Alfonso</span> López Ruiz </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/EnhancingBRDF2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/EnhancingBRDF2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_enhancing_2025" class="col-sm-8"> <div class="title">Enhancing LiDAR point cloud generation with BRDF-based appearance modelling</div> <div class="author"> Alfonso López, Carlos J. Ogayar, Rafael J. Segura, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Juan C. Casas-Rosa' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.isprsjprs.2025.02.010" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This work presents an approach to generating LiDAR point clouds with empirical intensity data on a massively parallel scale. Our primary aim is to complement existing real-world LiDAR datasets by simulating a wide spectrum of attributes, ensuring our generated data can be directly compared to real point clouds. However, our emphasis lies in intensity data, which conventionally has been generated using non-photorealistic shading functions. In contrast, we represent surfaces with Bidirectional Reflectance Distribution Functions (BRDF) obtained through goniophotometer measurements. We also incorporate refractivity indices derived from prior research. Beyond this, we simulate other attributes commonly found in LiDAR datasets, including RGB values, normal vectors, GPS timestamps, semantic labels, instance IDs, and return data. Our simulations extend beyond terrestrial scenarios; we encompass mobile and aerial scans as well. Our results demonstrate the efficiency of our solution compared to other state-of-the-art simulators, achieving an average decrease in simulation time of 85.62%. Notably, our approach introduces greater variability in the generated intensity data, accounting for material properties and variations caused by the incident and viewing vectors. The source code is available on GitHub (https://github.com/AlfonsoLRz/LiDAR_BRDF).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_enhancing_2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing {LiDAR} point cloud generation with {BRDF}-based appearance modelling}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{222}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0924-2716}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0924271625000607}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.isprsjprs.2025.02.010}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2025-03-27}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ISPRS Journal of Photogrammetry and Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Ogayar, Carlos J. and Segura, Rafael J. and Casas-Rosa, Juan C.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{LiDAR simulation, Bidirectional reflectance distribution function, Graphics processing unit, Virtual laser scanner}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{79--98}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/Virtualized2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/Virtualized2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="collado_virtualized_2025" class="col-sm-8"> <div class="title">Virtualized Point Cloud Rendering</div> <div class="author"> José Antonio Collado, Alfonso López, Juan Manuel Jurado, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Juan Roberto Jiménez' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Oct 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2025.3562696" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Remote sensing technologies, such as LiDAR, produce billions of points that commonly exceed the storage capacity of the GPU, restricting their processing and rendering. Level of detail (LoD) techniques have been widely investigated, but building the LoD structures is also time-consuming. This study proposes a GPU-driven culling system focused on determining the number of points visible in every frame. It can manipulate point clouds of any arbitrary size while maintaining a low memory footprint in both the CPU and GPU. Instead of organizing point clouds into hierarchical data structures, these are split into groups of points sorted using the Hilbert encoding. This alternative alleviates the occurrence of anomalous groups found in Morton curves. Instead of keeping the entire point cloud in the GPU, points are transferred on demand to ensure real-time capability. Accordingly, our solution can manipulate huge point clouds even in commodity hardware with low memory capacities. Moreover, hole filling is implemented to cover the gaps derived from insufficient density and our LoD system. Our proposal was evaluated with point clouds of up to 18 billion points, achieving an average of 80 frames per second (FPS) without perceptible quality loss. Relaxing memory constraints further enhances visual quality while maintaining an interactive frame rate. We assessed our method on real-world data, comparing it against three state-of-the-art methods, demonstrating its ability to handle significantly larger point clouds.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">collado_virtualized_2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtualized {Point} {Cloud} {Rendering}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1941-0506}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10972035}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TVCG.2025.3562696}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2025-10-03}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Visualization and Computer Graphics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Collado, José Antonio and López, Alfonso and Jurado, Juan Manuel and Jiménez, Juan Roberto}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Real-time systems, GPGPU, Rendering (computer graphics), acceleration structures, Colored noise, dynamic rendering, GPU-driven, Graphics processing units, Hardware, Image color analysis, Laser radar, level of detail, out-of-core rendering, Pipelines, Point cloud compression, point cloud rendering, point-based models, Random access memory, rasterization, virtual memory system, visibility}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8026--8039}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/ChangeDetection2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/ChangeDetection2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="casas-rosa_change_2024" class="col-sm-8"> <div class="title">Change Detection in Point Clouds Using 3D Fractal Dimension</div> <div class="author"> Juan C. Casas-Rosa, Pablo Navarro, Rafael J. Segura-Sánchez, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Antonio J. Rueda-Ruiz, Alfonso López-Ruiz, José M. Fuertes, Claudio Delrieux, Carlos J. Ogayar-Anguita' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Remote Sensing</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/rs16061054" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The management of large point clouds obtained by LiDAR sensors is an important topic in recent years due to the widespread use of this technology in a wide variety of applications and the increasing volume of data captured. One of the main applications of LIDAR systems is the study of the temporal evolution of the real environment. In open environments, it is important to know the evolution of erosive processes or landscape transformation. In the context of civil engineering and urban environments, it is useful for monitoring urban dynamics and growth, and changes during the construction of buildings or infrastructure facilities. The main problem with change detection (CD) methods is erroneous detection due to precision errors or the use of different capture devices at different times. This work presents a method to compare large point clouds, based on the study of the local fractal dimension of point clouds at multiple scales. Our method is robust in the presence of environmental and sensor factors that produce abnormal results with other methods. Furthermore, it is more stable than others in cases where there is no significant displacement of points but there is a local alteration of the structure of the point cloud. Furthermore, the precision can be adapted to the complexity and density of the point cloud. Finally, our solution is faster than other CD methods such as distance-based methods and can run at O(1) under some conditions, which is important when working with large datasets. All these improvements make the proposed method more suitable than the others to solve complex problems with LiDAR data, such as storage, time series data management, visualization, etc.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">casas-rosa_change_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Change {Detection} in {Point} {Clouds} {Using} {3D} {Fractal} {Dimension}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{http://creativecommons.org/licenses/by/3.0/}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2072-4292}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-4292/16/6/1054}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/rs16061054}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Casas-Rosa, Juan C. and Navarro, Pablo and Segura-Sánchez, Rafael J. and Rueda-Ruiz, Antonio J. and López-Ruiz, Alfonso and Fuertes, José M. and Delrieux, Claudio and Ogayar-Anguita, Carlos J.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{LiDAR, box counting, fractal dimension, point cloud comparison}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1054}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/EyeTrackingSurvey2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/EyeTrackingSurvey2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="moreno-arjonilla_eye-tracking_2024" class="col-sm-8"> <div class="title">Eye-tracking on virtual reality: a survey</div> <div class="author"> Jesús Moreno-Arjonilla, Alfonso López-Ruiz, J. Roberto Jiménez-Pérez, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'José E. Callejas-Aguilera, Juan M. Jurado' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Virtual Reality</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10055-023-00903-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Virtual reality (VR) has evolved substantially beyond its initial remit of gaming and entertainment, catalyzed by advancements such as improved screen resolutions and more accessible devices. Among various interaction techniques introduced to VR, eye-tracking stands out as a pivotal development. It not only augments immersion but offers a nuanced insight into user behavior and attention. This precision in capturing gaze direction has made eye-tracking instrumental for applications far beyond mere interaction, influencing areas like medical diagnostics, neuroscientific research, educational interventions, and architectural design, to name a few. Though eye-tracking’s integration into VR has been acknowledged in prior reviews, its true depth, spanning the intricacies of its deployment to its broader ramifications across diverse sectors, has been sparsely explored. This survey undertakes that endeavor, offering a comprehensive overview of eye-tracking’s state of the art within the VR landscape. We delve into its technological nuances, its pivotal role in modern VR applications, and its transformative impact on domains ranging from medicine and neuroscience to marketing and education. Through this exploration, we aim to present a cohesive understanding of the current capabilities, challenges, and future potential of eye-tracking in VR, underscoring its significance and the novelty of our contribution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">moreno-arjonilla_eye-tracking_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Eye-tracking on virtual reality: a survey}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1434-9957}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Eye-tracking on virtual reality}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10055-023-00903-y}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10055-023-00903-y}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Virtual Reality}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moreno-Arjonilla, Jesús and López-Ruiz, Alfonso and Jiménez-Pérez, J. Roberto and Callejas-Aguilera, José E. and Jurado, Juan M.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Virtual reality, Artificial Intelligence, Attention, Eye-tracking, Perception}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/ClassificationGrapevine2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/ClassificationGrapevine2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_classification_2024" class="col-sm-8"> <div class="title">Classification of Grapevine Varieties Using UAV Hyperspectral Imaging</div> <div class="author"> Alfonso López, Carlos J. Ogayar, Francisco R. Feito, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Joaquim J. Sousa' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Remote Sensing</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/rs16122103" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Classifying grapevine varieties is crucial in precision viticulture, as it allows for accurate estimation of vineyard row growth for different varieties and ensures authenticity in the wine industry. This task can be performed with time-consuming destructive methods, including data collection and analysis in the laboratory. In contrast, unmanned aerial vehicles (UAVs) offer a markedly more efficient and less restrictive method for gathering hyperspectral data, even though they may yield data with higher levels of noise. Therefore, the first task is the processing of these data to correct and downsample large amounts of data. In addition, the hyperspectral signatures of grape varieties are very similar. In this study, we propose the use of a convolutional neural network (CNN) to classify seventeen different varieties of red and white grape cultivars. Instead of classifying individual samples, our approach involves processing samples alongside their surrounding neighborhood for enhanced accuracy. The extraction of spatial and spectral features is addressed with (1) a spatial attention layer and (2) inception blocks. The pipeline goes from data preparation to dataset elaboration, finishing with the training phase. The fitted model is evaluated in terms of response time, accuracy and data separability and is compared with other state-of-the-art CNNs for classifying hyperspectral data. Our network was proven to be much more lightweight by using a limited number of input bands (40) and a reduced number of trainable weights (560 k parameters). Hence, it reduced training time (1 h on average) over the collected hyperspectral dataset. In contrast, other state-of-the-art research requires large networks with several million parameters that require hours to be trained. Despite this, the evaluated metrics showed much better results for our network (approximately 99% overall accuracy), in comparison with previous works barely achieving 81% OA over UAV imagery. This notable OA was similarly observed over satellite data. These results demonstrate the efficiency and robustness of our proposed method across different hyperspectral data sources.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_classification_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Classification of {Grapevine} {Varieties} {Using} {UAV} {Hyperspectral} {Imaging}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{http://creativecommons.org/licenses/by/3.0/}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2072-4292}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-4292/16/12/2103}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/rs16122103}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Ogayar, Carlos J. and Feito, Francisco R. and Sousa, Joaquim J.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{unmanned aerial vehicle, feature extraction, classification, deep learning, hyperspectral, grapevine}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2103}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/DetectionPhotovoltaic2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/DetectionPhotovoltaic2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cardoso_automated_2024" class="col-sm-8"> <div class="title">Automated detection and tracking of photovoltaic modules from 3D remote sensing data</div> <div class="author"> Andressa Cardoso, David Jurado-Rodríguez, Alfonso López, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'M. Isabel Ramos, Juan Manuel Jurado' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Applied Energy</em>, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.apenergy.2024.123242" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This study addresses the growing demand for increased performance and reliability of photovoltaic (PV) installations by developing innovative monitoring technologies. The strategy consists of flying an unmanned aerial vehicle (UAV) equipped with a dual camera (RGB and thermal) over the PV plant of interest, followed by the generation of photogrammetric 3D models derived from the overlapped aerial images. The resulting datasets involve orthoimages and point clouds by processing RGB and thermal imagery. The key contribution of this study is twofold: (1) the thermal image mapping on dense and high-resolution point clouds that represent the status and geometry of PV solar modules, and (2) the automatic identification of individual solar panels in 3D space and their thermal characterization along their oriented surface. Then, the vector layer of each PV panel is projected onto the 3D thermal point cloud to extract the thermal values associated with each panel. To evaluate the capability of the proposed method, it was replicated in different scenarios, considering rural and urban environments with different light conditions and PV structures. The results demonstrate the robustness of our method, which achieves a remarkably high detection rate, around 99.12% of true positives, and a low false positive rate, close to 0.88%. Consequently, this method means an advance over previous work by proposing a comprehensive and automated solution for individual and highly detailed monitoring of each solar panel from 3D remotely sensed data. This study opens up new frontier research related to real-time monitoring of photovoltaic modules, an inspection of solar photovoltaic cells, the simulation of solar resources and forecasting, the development of digital twins, solar radiation modelling, and analysis of modular floating solar farms under wave motion.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cardoso_automated_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated detection and tracking of photovoltaic modules from {3D} remote sensing data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{367}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0306-2619}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0306261924006251}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.apenergy.2024.123242}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Applied Energy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cardoso, Andressa and Jurado-Rodríguez, David and López, Alfonso and Ramos, M. Isabel and Jurado, Juan Manuel}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Thermography, 3D data fusion, Automatic detection, Geographic information system, Solar energy}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{123242}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/GeneratingImplicit2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/GeneratingImplicit2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_generating_2024" class="col-sm-8"> <div class="title">Generating implicit object fragment datasets for machine learning</div> <div class="author"> Alfonso López, Antonio J. Rueda, Rafael J. Segura, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Carlos J. Ogayar, Pablo Navarro, José M. Fuertes' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2024.104104" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>One of the primary challenges inherent in utilizing deep learning models is the scarcity and accessibility hurdles associated with acquiring datasets of sufficient size to facilitate effective training of these networks. This is particularly significant in object detection, shape completion, and fracture assembly. Instead of scanning a large number of real-world fragments, it is possible to generate massive datasets with synthetic pieces. However, realistic fragmentation is computationally intensive in the preparation (e.g., pre-factured models) and generation. Otherwise, simpler algorithms such as Voronoi diagrams provide faster processing speeds at the expense of compromising realism. In this context, it is required to balance computational efficiency and realism. This paper introduces a GPU-based framework for the massive generation of voxelized fragments derived from high-resolution 3D models, specifically prepared for their utilization as training sets for machine learning models. This rapid pipeline enables controlling how many pieces are produced, their dispersion and the appearance of subtle effects such as erosion. We have tested our pipeline with an archaeological dataset, producing more than 1M fragmented pieces from 1,052 Iberian vessels (Github). Although this work primarily intends to provide pieces as implicit data represented by voxels, triangle meshes and point clouds can also be inferred from the initial implicit representation. To underscore the unparalleled benefits of CPU and GPU acceleration in generating vast datasets, we compared against a realistic fragment generator that highlights the potential of our approach, both in terms of applicability and processing time. We also demonstrate the synergies between our pipeline and realistic simulators, which frequently cannot select the number and size of resulting pieces. To this end, a deep learning model was trained over realistic fragments and our dataset, showing similar results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_generating_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generating implicit object fragment datasets for machine learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{125}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0097-8493}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0097849324002395}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.cag.2024.104104}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers \&amp; Graphics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Rueda, Antonio J. and Segura, Rafael J. and Ogayar, Carlos J. and Navarro, Pablo and Fuertes, José M.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Voxel, Voronoi, Fracture dataset, Fragmentation, GPU programming}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104104}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/international/EUPVSEC24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/international/EUPVSEC24.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="de_sousa_cardoso_automatic_2024" class="col-sm-8"> <div class="title">Automatic Agrivoltaic Site Selection: a User-Friendly Interface powered by AHP Multicriteria Decision-Making</div> <div class="author"> Andressa Sousa Cardoso, Alfonso López Ruiz, María Isabel Ramos Galán, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Juan Manuel Jurado, Francisco Ramón Feito Higueruela' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 41st European Photovoltaic Solar Energy Conference and Exhibition</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4229/EUPVSEC2024/4DO.3.4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper presents an efficient approach to automatic agrivoltaic site selection, integrating a user-friendly interface with the Analytic Hierarchy Process (AHP) for multicriteria decision-making and advanced geospatial analysis. The goal is to empower users, including non-experts, with a practical tool for informed decision-making. Users provide raster and vector data from the region of interest and assign importance weights to layers. The software supports a wide range of spatial data, from solar exposure and slope to restricted areas, and allows for dynamic configuration of additional relevant layers. Layers can also include constraints, such as safety distances from structures. The tool optimizes site selection using efficient spatial searches with low computational complexity, while intermediate results are rendered in a graphic application. By evaluating criteria like solar exposure and topography, the application offers a systematic approach to site selection. Preliminary tests show promising results, and the final version is expected to deliver a valuable tool for sustainable agrivoltaic project planning.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">de_sousa_cardoso_automatic_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic {Agrivoltaic} {Site} {Selection}: a {User}-{Friendly} {Interface} powered by {AHP} {Multicriteria} {Decision}-{Making}}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-936338-90-4}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Automatic {Agrivoltaic} {Site} {Selection}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://userarea.eupvsec.org/proceedings/EU-PVSEC-2024/4do.3.4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.4229/EUPVSEC2024/4DO.3.4}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-11-15}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{41st {European} {Photovoltaic} {Solar} {Energy} {Conference} and {Exhibition}}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{WIP-Munich}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Sousa Cardoso, Andressa and López Ruiz, Alfonso and Ramos Galán, María Isabel and Jurado, Juan Manuel and Feito Higueruela, Francisco Ramón}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Dual Use and other Innovative PV Applications, PV Systems Engineering, Integrated/Applied PV}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{020422--001--020422--006}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/Metaheuristics2023.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/Metaheuristics2023.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_metaheuristics_2023" class="col-sm-8"> <div class="title">Metaheuristics for the optimization of Terrestrial LiDAR set-up</div> <div class="author"> Alfonso López, Carlos J. Ogayar, Juan M. Jurado, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Automation in Construction</em>, Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.autcon.2022.104675" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>3D point clouds have a significant impact on a wide range of applications, although their acquisition is frequently conditioned by the occlusion of the objects in the scene. To address this problem, this paper describes an approach for optimizing LiDAR (Light Detection and Ranging) surveys using metaheuristics such as local searches and genetic algorithms. The method generates a set of optimal scanning locations to densely cover the real-world environment represented through 3D synthetic models. Compared to previous research, this paper handles 3D occlusion by varying the height of the sensor. Also, previously used metrics are compressed into three functions to avoid multi-objective optimization. Regarding performance, a LiDAR scanning solution based on GPU (Graphics Processing Unit) hardware is used. Several tests were conducted to show that the combination of local searches and genetic algorithms generates a reduced set of locations capable of optimizing the scanning of buildings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_metaheuristics_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Metaheuristics for the optimization of {Terrestrial} {LiDAR} set-up}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{146}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0926-5805}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0926580522005453}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.autcon.2022.104675}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Automation in Construction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Ogayar, Carlos J. and Jurado, Juan M. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Genetic algorithm, LiDAR, GPGPU, Metaheuristic, Planning for Scanning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104675}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/Nested2023.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/Nested2023.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ogayar-anguita_nested_2023" class="col-sm-8"> <div class="title">Nested spatial data structures for optimal indexing of LiDAR data</div> <div class="author"> Carlos J. Ogayar-Anguita, Alfonso López-Ruiz, Antonio J. Rueda-Ruiz, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Rafael J. Segura-Sánchez' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, Jan 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.isprsjprs.2022.11.018" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In this paper we present a flexible framework for creating spatial data structures to manage LiDAR point clouds in the context of spatial big data. For this purpose, standard approaches typically include the use of a single data structure to index point clouds. Some of them use a hybrid two-tier solution to optimize specific application purposes such as storage or rendering. In this article we introduce a meta-structure that can have unlimited depth and a custom, user-defined combination of nested structures, such as grids, quadtrees, octrees, or kd-trees. With our approach, the out-of-core indexing of point clouds can be adapted to different types of datasets, taking into account the spatial distribution of the data. Therefore, the most suitable spatial indexing can be achieved for any type of dataset, from small TLS-based scenes to planetary-scale ALS-based scenes. This approach allows us to work with overlapping datasets of different resolutions from different acquisition technologies in the same structure.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ogayar-anguita_nested_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nested spatial data structures for optimal indexing of {LiDAR} data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{195}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0924-2716}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0924271622003112}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.isprsjprs.2022.11.018}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ISPRS Journal of Photogrammetry and Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ogayar-Anguita, Carlos J. and López-Ruiz, Alfonso and Rueda-Ruiz, Antonio J. and Segura-Sánchez, Rafael J.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{LiDAR, Spatial big data, Spatial data structure, Ubiquitous Point Cloud}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{287--297}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/EfficientGeneration2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/EfficientGeneration2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_efficient_2023" class="col-sm-8"> <div class="title">Efficient generation of occlusion-aware multispectral and thermographic point clouds</div> <div class="author"> Alfonso López, Carlos J. Ogayar, Juan M. Jurado, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Computers and Electronics in Agriculture</em>, Apr 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.compag.2023.107712" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The reconstruction of 3D point clouds from image datasets is a time-consuming task that has been frequently solved by performing photogrammetric techniques on every data source. This work presents an approach to efficiently build large and dense point clouds from co-acquired images. In our case study, the sensors co-acquire visible as well as thermal and multispectral imagery. Hence, RGB point clouds are reconstructed with traditional methods, whereas the rest of the data sources with lower resolution and less identifiable features are projected into the first one, i.e., the most complete and dense. To this end, the mapping process is accelerated using the Graphics Processing Unit (GPU) and multi-threading in the CPU (Central Processing Unit). The accurate colour aggregation in 3D points is guaranteed by taking into account the occlusion of foreground surfaces. Accordingly, our solution is shown to reconstruct much more dense point clouds than notable commercial software (286% on average), e.g., Pix4Dmapper and Agisoft Metashape, in much less time (−70% on average with respect to the best alternative).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_efficient_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient generation of occlusion-aware multispectral and thermographic point clouds}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{207}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0168-1699}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S016816992300100X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.compag.2023.107712}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers and Electronics in Agriculture}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Ogayar, Carlos J. and Jurado, Juan M. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{UAV, GPGPU, Multispectral, 3D point cloud, Thermography}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107712}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/LandscapeFeatures2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/LandscapeFeatures2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="collaro_detection_2023" class="col-sm-8"> <div class="title">Detection of landscape features with visible and thermal imaging at the Castle of Puerta Arenas</div> <div class="author"> Carolina Collaro, Carmen Enríquez-Muñoz, Alfonso López, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Carlos Enríquez, Juan M. Jurado' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Archaeological and Anthropological Sciences</em>, Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s12520-023-01831-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>There are some archaeological sites with hard accessibility which remain unexplored and barely documented. The use of unmanned aerial systems (UAS) alleviates this challenge with aerial observations monitored with distant remote control. In addition to acquiring images in the visible wavelengths, other devices can be coupled on aerial platforms to inspect beyond the remaining structure of an archaeological site. For instance, thermography has proven to be of great help in the detection of buried remains due to observed temperature anomalies. This work explores the Castle of Puerta Arenas fortress to build the first aerial 3D reconstruction of this site by using RGB and thermographic images collected from a UAS. Orthomosaics have been applied to hypothesize about the original shape of the fortress, whereas 3D reconstructions have been rather applied to visualization and analysis. In this regard, the explored remains have been processed as dense point clouds in the visible and long-wave infrared spectrum, with the latter leading to the detection of hypothetical and still unknown towers. The detection of anomalies has been automatized by performing statistical analyses, globally and limited to smaller 3D voxel neighbourhoods. As a result, the studied remains have been documented and observed from an unexplored perspective, helping their conservation and dissemination, as well as suggesting future excavations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">collaro_detection_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Detection of landscape features with visible and thermal imaging at the {Castle} of {Puerta} {Arenas}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1866-9565}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s12520-023-01831-3}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s12520-023-01831-3}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Archaeological and Anthropological Sciences}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Collaro, Carolina and Enríquez-Muñoz, Carmen and López, Alfonso and Enríquez, Carlos and Jurado, Juan M.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Photogrammetry, Structure from motion, Archaeology, Thermography, Unmanned aerial systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{152}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/VersionControl2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/VersionControl2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ogayar-anguita_version_2023" class="col-sm-8"> <div class="title">A Version Control System for Point Clouds</div> <div class="author"> Carlos J. Ogayar-Anguita, Alfonso López-Ruiz, Rafael J. Segura-Sánchez, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Antonio J. Rueda-Ruiz' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Remote Sensing</em>, Jan 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/rs15184635" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper presents a novel version control system for point clouds, which allows the complete editing history of a dataset to be stored. For each intermediate version, this system stores only the information that changes with respect to the previous one, which is compressed using a new strategy based on several algorithms. It allows undo/redo functionality in memory, which serves to optimize the operation of the version control system. It can also manage changes produced from third-party applications, which makes it ideal to be integrated into typical Computer-Aided Design workflows. In addition to automated management of incremental versions of point cloud datasets, the proposed system has a much lower storage footprint than the manual backup approach for most common point cloud workflows, which is essential when working with LiDAR (Light Detection and Ranging) data in the context of spatial big data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ogayar-anguita_version_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {Version} {Control} {System} for {Point} {Clouds}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{http://creativecommons.org/licenses/by/3.0/}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2072-4292}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-4292/15/18/4635}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/rs15184635}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ogayar-Anguita, Carlos J. and López-Ruiz, Alfonso and Segura-Sánchez, Rafael J. and Rueda-Ruiz, Antonio J.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{point cloud, LiDAR, incremental change logs, spatial big data, version control systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4635}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/thesis/PhD2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thesis/PhD2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_ruiz_nuevas_2023" class="col-sm-8"> <div class="title">Nuevas herramientas para la modelización de datos procedentes de sensores/new tools form modelling sensor data</div> <div class="author"> Alfonso López Ruiz </div> <div class="periodical"> Jan 2023 </div> <div class="periodical"> PhD Dissertation. Publisher: Universidad de Jaén </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">lopez_ruiz_nuevas_2023</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{{PhD} {Dissertation}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nuevas herramientas para la modelización de datos procedentes de sensores/new tools form modelling sensor data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López Ruiz, Alfonso}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{{PhD} {Dissertation}. Publisher: Universidad de Jaén}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/national/Kalathos2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/national/Kalathos2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="segura_kalathos_2022" class="col-sm-8"> <div class="title">Kalathos+: Construcción de datasets para la clasificación automática de fragmentos de vasijas cerámicas de torno</div> <div class="author"> Rafael J. Segura, Antonio J. Rueda, Carlos J. Ogáyar, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'José M. Fuertes, Ángel L. García-Fernández, Manuel J. Lucena, Alfonso López, Isabel Moreno, Manuel Molinos' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In </em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/ceig.20221145" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>En los últimos años las técnicas de aprendizaje profundo se han convertido en una poderosa alternativa a técnicas clásicas de aprendizaje automático orientadas a tareas de clasificación. Esta tecnología se ha aplicado con gran éxito en diversos campos, si bien es necesaria la existencia de un conjunto de datos etiquetados muy grande para afrontar el entrenamiento de las mismas. En este trabajo se presenta un framework para la generación automática de fragmentos de vasijas de cerámica de torno, convenientemente etiquetados, de manera que permitan el entrenamiento de CNNs para la clasificación de dichos fragmentos, y su posterior utilización en tareas de reconstrucción.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">segura_kalathos_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Kalathos+: {Construcción} de datasets para la clasificación automática de fragmentos de vasijas cerámicas de torno}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Attribution 4.0 International License}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-186-1}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Kalathos+}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://diglib.eg.org:443/xmlui/handle/10.2312/ceig20221145}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Segura, Rafael J. and Rueda, Antonio J. and Ogáyar, Carlos J. and Fuertes, José M. and García-Fernández, Ángel L. and Lucena, Manuel J. and López, Alfonso and Moreno, Isabel and Molinos, Manuel}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/ceig.20221145}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/international/Eurographics2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/international/Eurographics2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="collado_modeling_2022" class="col-sm-8"> <div class="title">Modeling and Enhancement of LiDAR Point Clouds from Natural Scenarios</div> <div class="author"> José Antonio Collado, Alfonso López, J. Roberto Jiménez-Pérez, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Lidia M. Ortega, Francisco R. Feito, Juan Manuel Jurado' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Eurographics 2022 - Posters</em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/egp.20221016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The generation of realistic natural scenarios is a longstanding and ongoing challenge in Computer Graphics. A common source of real-environmental scenarios is open point cloud datasets acquired by LiDAR (Laser Imaging Detection and Ranging) devices. However, these data have low density and are not able to provide sufficiently detailed environments. In this study, we propose a method to reconstruct real-world environments based on data acquired from LiDAR devices that overcome this limitation and generate rich environments, including ground and high vegetation. Additionally, our proposal segments the original data to distinguish among different kinds of trees. The results show that the method is capable of generating realistic environments with the chosen density and including specimens of each of the identified tree types.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">collado_modeling_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modeling and {Enhancement} of {LiDAR} {Point} {Clouds} from {Natural} {Scenarios}}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Attribution 4.0 International License}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-171-7}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://diglib.eg.org:443/xmlui/handle/10.2312/egp20221016}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Collado, José Antonio and López, Alfonso and Jiménez-Pérez, J. Roberto and Ortega, Lidia M. and Feito, Francisco R. and Jurado, Juan Manuel}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/egp.20221016}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eurographics 2022 - Posters}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/international/IGARSS2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/international/IGARSS2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_gpu-based_2022" class="col-sm-8"> <div class="title">GPU-based Mapping of Thermal Imagery for Generating 3D Occlusion-Aware Point Clouds</div> <div class="author"> Alfonso López, Juan M. Jurado, Carlos J. Ogayar, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IGARSS46834.2022.9884240" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This work describes an efficient approach for generating large 3D thermal point clouds considering the occlusion of camera viewpoints. For that purpose, RGB and thermal imagery are first corrected and fused with an intensity correlation-based algorithm. Then, absolute temperature values are obtained from the normalized data. Finally, thermal imagery is mapped on the point cloud using the Graphics Processing Unit (GPU) hardware. The proposed occlusion-aware mapping algorithm is massively parallelized using OpenGL’s compute shaders. Our solution allows generating dense thermal point clouds in a lower response time compared with other notable soft-ware solutions (e.g., Agisoft Metashape or Pix4Dmapper) that yield results with a significantly lower point density.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopez_gpu-based_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{GPU}-based {Mapping} of {Thermal} {Imagery} for {Generating} {3D} {Occlusion}-{Aware} {Point} {Clouds}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9884240}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IGARSS46834.2022.9884240}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IGARSS} 2022 - 2022 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Jurado, Juan M. and Ogayar, Carlos J. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1460--1463}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/national/GuidedModelling2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/national/GuidedModelling2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="collado_guided_2022" class="col-sm-8"> <div class="title">Guided Modeling of Natural Scenarios: Vegetation and Terrain</div> <div class="author"> José Antonio Collado, Alfonso López, Juan Roberto Jiménez Pérez, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Lidia M. Ortega, Juan M. Jurado, Francisco Feito' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In CEIG 2022 - Spanish Computer Graphics Conference</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/ceig.20221144" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The generation of realistic natural scenarios is a longstanding and ongoing challenge in Computer Graphics. LiDAR (Laser Imaging Detection and Ranging) point clouds have been gaining interest for the representation and analysis of real-world scenarios. However, the output of these sensors is conditioned by several parameters, including, but not limited to, distance to scanning target, aperture angle, number of laser beams, as well as systematic and random errors for the acquisition process. Hence, LiDAR point clouds may present inaccuracies and low density, thus hardening their visualization. In this work, we propose reconstructing the surveyed environments to enhance the point cloud density and provide a 3D representation of the scenario. To this end, ground and vegetation layers are detected and parameterized to allow their reconstruction. As a result, point clouds of any required density can be modeled, as well as 3D realistic natural scenarios that may lead to procedural generation through their parameterization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">collado_guided_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Guided {Modeling} of {Natural} {Scenarios}: {Vegetation} and {Terrain}}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Attribution 4.0 International License}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-186-1}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Guided {Modeling} of {Natural} {Scenarios}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CEIG 2022 - Spanish Computer Graphics Conference}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://diglib.eg.org:443/handle/10.2312/ceig20221144}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Collado, José Antonio and López, Alfonso and Pérez, Juan Roberto Jiménez and Ortega, Lidia M. and Jurado, Juan M. and Feito, Francisco}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/ceig.20221144}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/LiDAR2022.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/LiDAR2022.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_gpu-accelerated_2022" class="col-sm-8"> <div class="title">A GPU-Accelerated Framework for Simulating LiDAR Scanning</div> <div class="author"> Alfonso López, Carlos J. Ogayar, Juan M. Jurado, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Transactions on Geoscience and Remote Sensing</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TGRS.2022.3165746" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In this work, we present an efficient graphics processing unit (GPU)-based light detection and ranging (LiDAR) scanner simulator. Laser-based scanning is a useful tool for applications ranging from reverse engineering or quality control at an object scale to large-scale environmental monitoring or topographic mapping. Beyond that, other specific applications require a large amount of LiDAR data during development, such as autonomous driving. Unfortunately, it is not easy to get a sufficient amount of ground-truth data due to time constraints and available resources. However, LiDAR simulation can generate classified data at a reduced cost. We propose a parameterized LiDAR to emulate a wide range of sensor models from airborne to terrestrial scanning. OpenGL’s compute shaders are used to massively generate beams emitted by the virtual LiDAR sensors and solve their collision with the surrounding environment even with multiple returns. Our work is mainly intended for the rapid generation of datasets for neural networks, consisting of hundreds of millions of points. The conducted tests show that the proposed approach outperforms a sequential LiDAR scanning. Its capabilities for generating huge labeled datasets have also been shown to improve previous studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_gpu-accelerated_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {GPU}-{Accelerated} {Framework} for {Simulating} {LiDAR} {Scanning}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{60}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-0644}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9751040}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TGRS.2022.3165746}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Geoscience and Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Ogayar, Carlos J. and Jurado, Juan M. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--18}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/Strategies2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/Strategies2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bejar-martos_strategies_2022" class="col-sm-8"> <div class="title">Strategies for the Storage of Large LiDAR Datasets—A Performance Comparison</div> <div class="author"> Juan A. Béjar-Martos, Antonio J. Rueda-Ruiz, Carlos J. Ogayar-Anguita, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Rafael J. Segura-Sánchez, Alfonso López-Ruiz' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Remote Sensing</em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/rs14112623" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The widespread use of LiDAR technologies has led to an ever-increasing volume of captured data that pose a continuous challenge for its storage and organization, so that it can be efficiently processed and analyzed. Although the use of system files in formats such as LAS/LAZ is the most common solution for LiDAR data storage, databases are gaining in popularity due to their evident advantages: centralized and uniform access to a collection of datasets; better support for concurrent retrieval; distributed storage in database engines that allows sharding; and support for metadata or spatial queries by adequately indexing or organizing the data. The present work evaluates the performance of four popular NoSQL and relational database management systems with large LiDAR datasets: Cassandra, MongoDB, MySQL and PostgreSQL. To perform a realistic assessment, we integrate these database engines in a repository implementation with an elaborate data model that enables metadata and spatial queries and progressive/partial data retrieval. Our experimentation concludes that, as expected, NoSQL databases show a modest but significant performance difference in favor of NoSQL databases, and that Cassandra provides the best overall database solution for LiDAR data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bejar-martos_strategies_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Strategies for the {Storage} of {Large} {LiDAR} {Datasets}—{A} {Performance} {Comparison}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{http://creativecommons.org/licenses/by/3.0/}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2072-4292}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-4292/14/11/2623}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/rs14112623}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Béjar-Martos, Juan A. and Rueda-Ruiz, Antonio J. and Ogayar-Anguita, Carlos J. and Segura-Sánchez, Rafael J. and López-Ruiz, Alfonso}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{LiDAR, point clouds, databases, NoSQL}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2623}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/HyperspectralPointClouds2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/HyperspectralPointClouds2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_generation_2022" class="col-sm-8"> <div class="title">Generation of hyperspectral point clouds: Mapping, compression and rendering</div> <div class="author"> Alfonso López, Juan M. Jurado, J. Roberto Jiménez-Pérez, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Computers &amp; Graphics</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.cag.2022.06.011" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Hyperspectral data are being increasingly used for the characterization and understanding of real-world scenarios. In this field, UAV-based sensors bring the opportunity to collect multiple samples from different viewpoints. Thus, light-material interactions of real objects may be observed in outdoor scenarios with a significant spatial resolution (5 cm/pixel). Nevertheless, the generation of hyperspectral 3D data still poses challenges in post-processing due to the high geometric deformation of images. Most of the current solutions use both LiDAR (Light Detection and Ranging) and hyperspectral sensors, which are integrated into the same acquisition system. However, these present several limitations due to errors derived from inertial measurements for data fusion and the spatial resolution according to the LiDAR capabilities. In this work, a method is proposed for the generation of hyperspectral point clouds. Input data are formed by push-broom hyperspectral images and 3D point clouds. On the one hand, the point clouds may be obtained by applying a typical photogrammetric workflow or LiDAR technology. Then, hyperspectral images are geometrically corrected and aligned with the RGB orthomosaic. Accordingly, hyperspectral data are ready to be mapped on the 3D point cloud. This procedure is implemented on the GPU by testing which points are visible for each pixel of the hyperspectral imagery. This work also provides a novel solution to generate, compress and render 3D hyperspectral point clouds, enabling the study of geometry and the hyperspectral response of natural and artificial materials in the real world.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_generation_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generation of hyperspectral point clouds: {Mapping}, compression and rendering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{106}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0097-8493}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Generation of hyperspectral point clouds}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0097849322001145}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.cag.2022.06.011}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers \&amp; Graphics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Jurado, Juan M. and Jiménez-Pérez, J. Roberto and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Massively parallel algorithms, Hyperspectral, Compression, Rendering}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{267--276}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/RemoteSensingSurvey2022.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/RemoteSensingSurvey2022.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jurado_remote_2022" class="col-sm-8"> <div class="title">Remote sensing image fusion on 3D scenarios: A review of applications for agriculture and forestry</div> <div class="author"> Juan M. Jurado, Alfonso López, Luís Pádua, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Joaquim J. Sousa' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>International Journal of Applied Earth Observation and Geoinformation</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.jag.2022.102856" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Three-dimensional (3D) image mapping of real-world scenarios has a great potential to provide the user with a more accurate scene understanding. This will enable, among others, unsupervised automatic sampling of meaningful material classes from the target area for adaptive semi-supervised deep learning techniques. This path is already being taken by the recent and fast-developing research in computational fields, however, some issues related to computationally expensive processes in the integration of multi-source sensing data remain. Recent studies focused on Earth observation and characterization are enhanced by the proliferation of Unmanned Aerial Vehicles (UAV) and sensors able to capture massive datasets with a high spatial resolution. In this scope, many approaches have been presented for 3D modeling, remote sensing, image processing and mapping, and multi-source data fusion. This survey aims to present a summary of previous work according to the most relevant contributions for the reconstruction and analysis of 3D models of real scenarios using multispectral, thermal and hyperspectral imagery. Surveyed applications are focused on agriculture and forestry since these fields concentrate most applications and are widely studied. Many challenges are currently being overcome by recent methods based on the reconstruction of multi-sensorial 3D scenarios. In parallel, the processing of large image datasets has recently been accelerated by General-Purpose Graphics Processing Unit (GPGPU) approaches that are also summarized in this work. Finally, as a conclusion, some open issues and future research directions are presented.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jurado_remote_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Remote sensing image fusion on {3D} scenarios: {A} review of applications for agriculture and forestry}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{112}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1569-8432}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Remote sensing image fusion on {3D} scenarios}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1569843222000589}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jag.2022.102856}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Applied Earth Observation and Geoinformation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jurado, Juan M. and López, Alfonso and Pádua, Luís and Sousa, Joaquim J.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{3D Modeling, Data Fusion, Image Mapping, Survey}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102856}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/TreeBranching2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/TreeBranching2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cardenas_reconstruction_2022" class="col-sm-8"> <div class="title">Reconstruction of tree branching structures from UAV-LiDAR data</div> <div class="author"> José L. Cárdenas, Alfonso López, Carlos J. Ogayar, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Francisco R. Feito, Juan M. Jurado' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Frontiers in Environmental Science</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The reconstruction of tree branching structures is a longstanding problem in Computer Graphics which has been studied over several data sources, from photogrammetry point clouds to Terrestrial and Aerial Laser Imaging Detection and Ranging technology. However, most data sources present acquisition errors that make the reconstruction more challenging. Among them, the main challenge is the partial or complete occlusion of branch segments, thus leading to disconnected components whether the reconstruction is resolved using graph-based approaches. In this work, we propose a hybrid method based on radius-based search and Minimum Spanning Tree for the tree branching reconstruction by handling occlusion and disconnected branches. Furthermore, we simplify previous work evaluating the similarity between ground-truth and reconstructed skeletons. Using this approach, our method is proved to be more effective than the baseline methods, regarding reconstruction results and response time. Our method yields better results on the complete explored radii interval, though the improvement is especially significant on the Ground Sampling Distance In terms of latency, an outstanding performance is achieved in comparison with the baseline method.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cardenas_reconstruction_2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reconstruction of tree branching structures from {UAV}-{LiDAR} data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2296-665X}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fenvs.2022.960083}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Environmental Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cárdenas, José L. and López, Alfonso and Ogayar, Carlos J. and Feito, Francisco R. and Jurado, Juan M.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/national/ComparisonGPU2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/national/ComparisonGPU2021.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_comparison_2021" class="col-sm-8"> <div class="title">Comparison of GPU-based Methods for Handling Point Cloud Occlusion</div> <div class="author"> Alfonso López, Juan Manuel Jurado, Emilio José Padrón, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Carlos Javier Ogayar, Francisco Ramón Feito' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In CEIG 2021 - Spanish Computer Graphics Conference</em>, Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/ceig.20211364" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Three-dimensional point clouds have conventionally been used along with several sources of information. This fusion can be performed by projecting the point cloud into the image plane and retrieving additional data for each point. Nevertheless, the raw projection omits the occlusion caused by foreground surfaces, thus assigning wrong information to 3D points. For large point clouds, testing the occlusion of each point from every viewpoint is a time-consuming task. Hence, we propose several algorithms implemented in GPU and based on the use of z-buffers. Given the size of nowadays point clouds, we also adapt our methodologies to commodity hardware by splitting the point cloud into several chunks. Finally, we compare their performance through the response time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopez_comparison_2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Comparison of {GPU}-based {Methods} for {Handling} {Point} {Cloud} {Occlusion}}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-160-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://diglib.eg.org:443/xmlui/handle/10.2312/ceig20211364}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Jurado, Juan Manuel and Padrón, Emilio José and Ogayar, Carlos Javier and Feito, Francisco Ramón}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/ceig.20211364}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CEIG 2021 - Spanish Computer Graphics Conference}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/conferences/national/LiDAR2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conferences/national/LiDAR2021.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_gpu-accelerated_2021" class="col-sm-8"> <div class="title">A GPU-accelerated LiDAR Sensor for Generating Labelled Datasets</div> <div class="author"> Alfonso López, Carlos Javier Ogayar Anguita, and Francisco Ramón Feito Higueruela </div> <div class="periodical"> <em>In CEIG 2021 - Spanish Computer Graphics Conference</em>, Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/ceig.20211360" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper presents a GPU-based LiDAR simulator to generate large datasets of ground-truth point clouds. LiDAR technology has significantly increased its impact on academic and industrial environments. However, some of its applications require a large amount of annotated LiDAR data. Furthermore, there exist many types of LiDAR sensors. Therefore, developing a parametric LiDAR model allows simulating a wide range of LiDAR scanning technologies and obtaining a significant number of points clouds at no cost. Beyond their intensity data, these synthetic point clouds can be classified with any level of detail.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopez_gpu-accelerated_2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {GPU}-accelerated {LiDAR} {Sensor} for {Generating} {Labelled} {Datasets}}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-160-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://diglib.eg.org:443/xmlui/handle/10.2312/ceig20211360}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-01-02}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Anguita, Carlos Javier Ogayar and Higueruela, Francisco Ramón Feito}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/ceig.20211360}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CEIG 2021 - Spanish Computer Graphics Conference}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/Framework2021.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/Framework2021.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_framework_2021" class="col-sm-8"> <div class="title">A framework for registering UAV-based imagery for crop-tracking in Precision Agriculture</div> <div class="author"> Alfonso López, Juan M. Jurado, Carlos J. Ogayar, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>International Journal of Applied Earth Observation and Geoinformation</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.jag.2020.102274" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Multiple types of images provide useful information about a crop, but image fusion is still a challenge in Precision Agriculture (PA). We describe a framework which manages a multi-layer registration model of heterogeneous images obtained by an unmanned aerial vehicle (UAV) by proposing pair-to-pair steps through a registration method invariant to intensity differences, allowing us to connect different aerial images with significant differences. Correction of deformed images is treated as a first step to end up with our registration algorithms. These methods conform the base of more advanced systems that combine 2D and spatial information, therefore it represents the link of several types of images. The evaluation shows the flexibility of our framework when dealing with different requirements. Effectiveness of the Enhanced Correlation Coefficient method is proved and thus shown as a suitable method for the registration of heterogeneous images.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_framework_2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A framework for registering {UAV}-based imagery for crop-tracking in {Precision} {Agriculture}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{97}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1569-8432}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S030324342030917X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jag.2020.102274}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Applied Earth Observation and Geoinformation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Jurado, Juan M. and Ogayar, Carlos J. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Image registration, Multispectral imagery, Thermal imagery, Tree recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102274}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/journals/OptimizedApproach2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="journals/OptimizedApproach2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_optimized_2021" class="col-sm-8"> <div class="title">An optimized approach for generating dense thermal point clouds from UAV-imagery</div> <div class="author"> Alfonso López, Juan M. Jurado, Carlos J. Ogayar, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Francisco R. Feito' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.isprsjprs.2021.09.022" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Thermal infrared (TIR) images acquired from Unmanned Aircraft Vehicles (UAV) are gaining scientific interest in a wide variety of fields. However, the reconstruction of three-dimensional (3D) point clouds utilizing consumer-grade TIR images presents multiple drawbacks as a consequence of low-resolution and induced aberrations. Consequently, these problems may lead photogrammetric techniques, such as Structure from Motion (SfM), to generate poor results. This work proposes the use of RGB point clouds estimated from SfM as the input for building thermal point clouds. For that purpose, RGB and thermal imagery are registered using the Enhanced Correlation Coefficient (ECC) algorithm after removing acquisition errors, thus allowing us to project TIR images into an RGB point cloud. Furthermore, we consider several methods to provide accurate thermal values for each 3D point. First, the occlusion problem is solved through two different approaches, so that points that are not visible from a viewing angle do not erroneously receive values from foreground objects. Then, we propose a flexible method to aggregate multiple thermal values considering the dispersion from such aggregation to the image samples. Therefore, it minimizes error measurements. A naive classification algorithm is then applied to the thermal point clouds as a case study for evaluating the temperature of vegetation and ground points. As a result, our approach builds thermal point clouds with up to 798,69% more point density than results from other commercial solutions. Moreover, it minimizes the build time by using parallel computing for time-consuming tasks. Despite obtaining larger point clouds, we report up to 96,73% less processing time per 3D point.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopez_optimized_2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An optimized approach for generating dense thermal point clouds from {UAV}-imagery}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{182}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0924-2716}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0924271621002604}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.isprsjprs.2021.09.022}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2023-12-31}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ISPRS Journal of Photogrammetry and Remote Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López, Alfonso and Jurado, Juan M. and Ogayar, Carlos J. and Feito, Francisco R.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{GPU computing, Point cloud, Image processing, Occlusion, Thermal imagery, UAV imagery}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{78--95}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/thesis/TFM2020.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thesis/TFM2020.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_ruiz_simulacion_2020" class="col-sm-8"> <div class="title">Simulación de escaneados 3D</div> <div class="author"> Alfonso López Ruiz </div> <div class="periodical"> Jun 2020 </div> <div class="periodical"> Master Dissertation. Publisher: Universidad de Jaén </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Las nubes de puntos 3D procedentes de un sensor LiDAR se utilizan en un número considerable de aplicaciones: desde la preparación y verificación de trabajos de campo, a tareas relacionadas con la inteligencia artificial, como puede ser la conducción autónoma o el entrenamiento de sistemas robóticos. Sin embargo, su obtención representa un coste económico y temporal, y más allá de la adquisición, se observa un número muy reducido de conjuntos de datos etiquetados aplicables a tareas de machine learning y de visión por computador. Además, es común encontrar nubes de puntos cuyas etiquetas se reducen a unas pocas clases, que incluso se asignan manualmente, lo que implica que podrían existir errores en el proceso de etiquetado, más allá del limitado nivel de detalle existente. Por tanto, la simulación de un sensor LiDAR sobre un escenario 3D modelado permite obtener nubes de puntos sintéticas, correctamente etiquetadas, con clases ajustadas a un escenario concreto, y con un nivel de detalle personalizado. Por otro lado, la generación de nubes de puntos en gran cantidad puede obtenerse como consecuencia de la introducción de escenarios procedurales. El comportamiento físico del sensor hace que este problema pueda representar una elevada carga de trabajo. Por tanto, la introducción de la computación paralela puede ayudar a reducir el tiempo de respuesta del proceso de escaneo. Además, la simulación del sensor no sólo incluye una generación básica de una nube de puntos, sino también la introducción de aquellos errores más comunes vinculados a un dispositivo LiDAR, con el fin de reproducir de la manera más fiel posible su comportamiento.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@thesis</span><span class="p">{</span><span class="nl">lopez_ruiz_simulacion_2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Simulación de escaneados {3D}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hdl.handle.net/10953.1/19941}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{spa}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2025-11-26}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López Ruiz, Alfonso}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{{Master} {Dissertation}. Publisher: Universidad de Jaén}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{{Master} {Dissertation}}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/thesis/TFG2019.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thesis/TFG2019.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lopez_ruiz_prototipo_2019" class="col-sm-8"> <div class="title">Prototipo de control avanzado de grandes plantaciones mediante teledetección</div> <div class="author"> Alfonso López Ruiz </div> <div class="periodical"> Jun 2019 </div> <div class="periodical"> Bachelor Dissertation. Publisher: Universidad de Jaén </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>La tecnología, y por lo tanto la agricultura de precisión, suponen un factor clave para la consecución del aumento de la producción en la agricultura de la forma más óptima posible. Se propone así en este trabajo la utilización de datos de varios sensores (multiespectrales, térmicos, etc) para obtener información útil de un cultivo, no sin antes revertir todos los errores que puedan contener las capturas realizadas, de tal manera que estas se transforman hasta alcanzar un estado que se considera óptimo para el estudio. Se definen pues una serie de algoritmos y operaciones para la consecución de objetivos tales como la extracción de árboles o la georreferenciación de puntos de una imagen. Habrá que probar la viabilidad de dichos algoritmos para su introducción en una futura aplicación de utilidad para el agricultor.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@thesis</span><span class="p">{</span><span class="nl">lopez_ruiz_prototipo_2019</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Prototipo de control avanzado de grandes plantaciones mediante teledetección}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hdl.handle.net/10953.1/14302}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{spa}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2025-11-26}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{López Ruiz, Alfonso}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{{Bachelor} {Dissertation}. Publisher: Universidad de Jaén}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{{Bachelor} {Dissertation}}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Alfonso López Ruiz. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>